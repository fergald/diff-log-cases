---
title: "Demonstrate problems with using diff(log(cumulative cases)) with NPIs"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

A demonstration of some unfortunate properties of the method used in
[Hsiang](https://onlinelibrary.wiley.com/doi/full/10.1111/eci.13553) and
[Bendavid](https://onlinelibrary.wiley.com/doi/full/10.1111/eci.13484)

# Setup machinary

We create some machinery for running the SEIR model with NPIs and then
performing a linear regression on diff(log(cumulative case counts)).

```{r setup_seir}
source("seir.R")

#' Run linear regression against the diff of the log of case numbers with NPIs.
#' 
#' @param y a vector of case numbers
#' @param npis a dataframe of daily NPI multiplicative effects on R_0, one
#'     column for each NPI.
runRegression = function(y, npis) {
  l_y = log(y)
  d_l_y = diff(l_y)
  npi_names = names(npis)
  n = length(d_l_y)
  # Just in case there's a mismatch in length between the NPIs and the case data
  if (n < length(npis[[1]])) {
    warning(("truncating npis"))
    npis = lapply(npis, head, n)
  }
  # Construct a frame of 0s and 1s to indicate when an NPI was/wasn't active
  # I.e. when it's multiplicative effect was different to 1.
  data = data.frame(lapply(npis, sapply, function(r) {
    if (r == 1)
      0
    else
      1
  }))

  # Add the case data.  
  data$d_l_y = d_l_y
  
  # Construct the format for the regression which will be
  # "d_l_y = npi_1 + npi_2 + ..."
  reg_terms = npi_names
  npi_formula = paste(reg_terms, collapse = " + ")

  r.model = lm(paste("d_l_y", npi_formula, sep = " ~ "), data = data)
  #print(summary(r.model))
  coefficients = r.model$coefficients

  # Return the coefficients and e^c for each coefficient.
  data.frame("coeffs" = coefficients,
             "exp(coeffs)" = exp(coefficients))
}

# Set up things, solve the SEIR model and run the regression.
generateRegression = function(population, r_0, end_day, npis) {
  # It takes a while for the model to produce an infected case, so to ensure
  # that we start from the day of the first infected case, we do extend things.
  start_day = findFirstInfection(population, r_0, end_day)
  end_day = end_day + start_day
  rates = append(rep(1, start_day), mergeNPIs(npis))
  
  # Run the SEIR model.
  model = as.data.frame(seirModel(POPULATION, r_0, end_day, rates))
  
  # Regress against cumulative cases.
  cumulative_cases = (model$I + model$R)[start_day:end_day]
  runRegression(cumulative_cases, npis)
}

```

We then choose some parameters for our simulated outbreak.
The other parameters of the SEIR model are fixed,
taken from [Piovella](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7445013/),
see [seir.R](./seir.R).

```{r params}
POPULATION = 10*1000*1000
R_0 = 2.4
DAYS = 30

#' Wrap it all up in a simple function.
regressWithNPIs = function(npis) {
  generateRegression(POPULATION, R_0, DAYS, NPIs(npis))
}
```

# Bad results

## Strong NPIs are not seen as strong

This NPI reduces spread by a factor of $100$.
It essentially ends the outbreak on day 21.

```{r npi_end}
regressWithNPIs(list(NPI(0.01, 21, DAYS)))
```
It is seen as slightly weaker than
a $0.5\times$ NPI on day 5
(which only cuts $R_0$ to $1.2$,
allowing exponential growth to continue)
$-0.1084048 < -0.1077125$.

Being based on cumulative numbers,
the method has a major blind-spot for strong NPIs.
The ratio of cumulative cases is bounded below by $1$
but is unbounded above
this means that once $R<1$
the measurement greatly loses sensitivity.

```{r npi_not_end}
regressWithNPIs(list(NPI(0.5, 5, DAYS)))
```

## Measured impact is highly dependent on start day

Here, the same strength NPI ($0.5\times$) is initiated on a range of days
resulting in widely varying weights

```{r by_start_day}
by_start_day = d=data.frame("start_day"=rep(NA, 29), "coeff"=rep(NA, 29))
for (d in 2:30) {
  r = regressWithNPIs(list(NPI(.5, d, DAYS)))
  by_start_day[d, ] = list(d, r$coeff[2])
}
knitr::kable(by_start_day)
```

### Comparison

Compare $.5\times$ on day 21 with, $0.78\times$ on day 5.
They are both considered approximately equal.

```{r npi_equal_21}
regressWithNPIs(list(NPI(.5, 21, DAYS)))
```

```{r npi_equal_diff}
regressWithNPIs(list(NPI(.78, 5, DAYS)))
```

## Bad NPI looks good

The first NPI here *increases* spread by $1.1\times$ 
and the second decreases spread by $0.9\times$
but the regression finds them to be almost equal.
```{r npi_bad_looks_good}
regressWithNPIs(list(NPI(1.1, 11, DAYS),
                     NPI(0.9, 21, DAYS)))
```

Reordering them partly corrects this
however the second one is still measured as decreasing spread.

```{r npi_bad_looks_good_order}
regressWithNPIs(list(NPI(0.9, 11, DAYS),
                     NPI(1.1, 21, DAYS)))
```

Worse, the earlier a "bad" NPI starts, the better it looks.

Here is a $1.1\times$ NPI starting on day 5.
```{r npi_bad_5}
regressWithNPIs(list(NPI(1.1, 5, DAYS)))
```

Here's the same NPI starting on day 11
```{r npi_bad_11}
regressWithNPIs(list(NPI(1.1, 11, DAYS)))
```
## A series of equal NPIs is seen as unequal

Here we apply 3 NPIs of the same strength ($0.5\times$) cumulatively,
starting on different days.
Note also that the first NPI is $0.5\times$ on day 11.
When occurring as the only NPI,
it was weighted as $-0.0919526$
but here it's weighted as $-0.06934883$
simply due to the NPIst that follow it.

```{r npi_triple}
regressWithNPIs(list(NPI(0.5, 11, DAYS),
                     NPI(0.5, 21, DAYS),
                     NPI(0.5, 25, DAYS)))
```

# Conclusion

The method may be able to detect whether the overall impact
of a group of NPI was to reduce spread
but it is quite unsuitable for comparing NPIs
either within a country or across countries.
